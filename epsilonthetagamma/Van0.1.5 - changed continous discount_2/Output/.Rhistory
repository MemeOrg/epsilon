diabetes_hash[is.na(diabetes_hash)] = 0
diabetes_hash[is.na(diabetes_hash),] = 0
diabetes_hash[is.na(diabetes_hash)] = 0
summary(diabetes_hash)
View(diabetes_hash[diag_1])
View(diabetes_hash$diag_1)
diabetes_hash[is.na(diabetes_hash)] = 0
require(RCurl)
binData <- getBinaryURL("https://archive.ics.uci.edu/ml/machine-learning-databases/00296/datas
et_diabetes.zip",
ssl.verifypeer=FALSE)
conObj <- file("dataset_diabetes.zip", open = "wb")
writeBin(binData, conObj)
# don't fortet to close it
close(conObj)
# open diabetes file
files <- unzip("dataset_diabetes.zip")
diabetes <- read.csv(files[1], stringsAsFactors = FALSE)
diabetes = read.csv("C:\\Users\\Martin Nguyen\\Desktop\\diabetic_data.csv", stringAsFactors = FALSE)
# open diabetes file
files <- unzip("dataset_diabetes.zip")
diabetes <- read.csv(files[1], stringsAsFactors = FALSE)
# open diabetes file
files <- unzip("dataset_diabetes.zip")
diabetes <- read.csv(files[1], stringsAsFactors = FALSE)
# open diabetes file
files <- unzip("dataset_diabetes.zip")
diabetes <- read.csv(files[1], stringsAsFactors = FALSE)
# open diabetes file
files <- unzip("dataset_diabetes.zip")
diabetes <- read.csv(files[1], stringsAsFactors = FALSE)
diabetes = read.csv("C:\\Users\\Martin Nguyen\\Desktop\\diabetic_data.csv", stringsAsFactors = FALSE)
str(diabetes)
diabetes <- subset(diabetes,select=-c(encounter_id, patient_nbr))
# transform all "?" to 0s
diabetes[diabetes == "?"] <- NA
# remove zero variance - ty James http://stackoverflow.com/questions/8805298/quickly-remove-ze
ro-variance-variables-from-a-data-frame
diabetes <- diabetes[sapply(diabetes, function(x) length(levels(factor(x,exclude=NULL)))>1)]
# prep outcome variable to those readmitted under 30 days
diabetes$readmitted <- ifelse(diabetes$readmitted == "<30",1,0)
outcomeName <- 'readmitted'
diabetes_hash <- diabetes
predictorNames <- setdiff(names(diabetes_hash),outcomeName)
# change all NAs to 0
diabetes_hash[is.na(diabetes_hash)] <- 0
library(caret)
set.seed(1234)
split <- sample(nrow(diabetes_hash), floor(0.5*nrow(diabetes_hash)))
objTrain <-diabetes_hash[split,]
objTest <- diabetes_hash[-split,]
library(FeatureHashing)
objTrain_hashed = hashed.model.matrix(~., data=objTrain[,predictorNames], hash_size=2^12, transspose=FALSE, keep.hashing_mapping=TRUE)
library(FeatureHashing)
objTrain_hashed = hashed.model.matrix(~., data=objTrain[,predictorNames], hash_size=2^12, transpose=FALSE, keep.hashing_mapping=TRUE)
objTrain_hashed = as(objTrain_hashed, "dgCMatrix")
objTest_hashed = hashed.model.matrix(~., data=objTest[,predictorNames], hash_size=2^12, transpose=FALSE, keep.hashing_mapping=TRUE)
objTest_hashed = as(objTest_hashed, "dgCMatrix")
library(glmnet)
glmnetModel <- cv.glmnet(objTrain_hashed, objTrain[,outcomeName],family = "binomial", type.measure = "auc")
glmnetPredict <- predict(glmnetModel, objTest_hashed, s="lambda.min")
auc(objTest[,outcomeName], glmnetPredict)
help(auc)
FeatureHashing
??FeatureHashing
help(glmnet)
help(GetSummaryPlot)
getModelInfo()$rpart$type
getModelInfo()$svm$type
getModelInfo()$svmPoly$type
train = read.csv("C:\\Users\\Martin Nguyen\\Desktop\\train.csv")
titanic = read.table("C:\\Users\\Martin Nguyen\\Desktop\\titanic.txt")
titanic = read.table("C:\\Users\\Martin Nguyen\\Desktop\\titanic.txt", sep = ",")
View(titanic)
titanic = read.table("C:\\Users\\Martin Nguyen\\Desktop\\titanic.txt", sep = " ")
View(titanic)
titanic = read.table("C:\\Users\\Martin Nguyen\\Desktop\\titanic.txt", sep = "\t")
View(titanic)
titanic = read.table("C:\\Users\\Martin Nguyen\\Desktop\\titanic.txt", sep = "\t", header = TRUE)
View(titanic)
install.packages("party")
library(genefilter)
help(rowttests)
library(tissuesGeneExpression)
data(tissuesGeneExpression
)
y = e - rowMeans(e)
s = svd(y)
z = s$d * t(s$v)
library(rafalib)
ftissue = factor(tissue)
mypar2(1,1)
plot(z[1,],z[2,],col=as.numeric(ftissue))
legend("topleft",levels(ftissue),col=seq_along(ftissue),pch=1)
library(rafalib)
ftissue = factor(tissue)
mypar2(1,2)
plot(z[1,],z[2,],col=as.numeric(ftissue))
legend("topleft",levels(ftissue),col=seq_along(ftissue),pch=1)
plot(mds[,1],mds[,2],col=as.numeric(ftissue))
d = dist(t(e))
mds = cmdscale(d)
plot(mds[,1],mds[,2],col=as.numeric(ftissue))
help(cmdscale)
dim(e)
help(svd)
library(Biobase)
library(GSE5859Subset)
data(GSE5859Subset)
y = geneExpression - rowMeans(geneExpression)
pcs = svd(y)
sd(pcs$v[,1])
sd(pcs$v[,2])
sd(pcs$v[,3])
sd(pcs$v[1,])
sd(pcs$v[2,])
pcs = svd(y)$v[,1:2]
o = order(sampleInfo$date)
cols = as.numeric(month)[o]
mypar2(2,1)
for(i in 1:2){
plot(pcs[o,i],col=cols,xaxt="n",xlab="")
label = gsub("2005-","",sampleInfo$date[o])
axis(1,1:ncol(y),label,las=2)
}
library(tissuesGeneExpression)
data(tissuesGeneExpression)
y = e - rowMeans(e)
s = svd(y)
z = s$d * t(s$v)
cor(s$v[,1],s$v[,2])
cor(s$v[1,],s$v[2,])
cor(s$v[1,],s$v[3,])
cor(s$v[1,],s$v[4,])
cor(s$v[1,],s$v[5,])
cor(s$[,1],s$v[,2])
cor(s$v[,1],s$v[,2])
cor(s$v[,1],s$v[,3])
cor(s$v[,1],s$v[,4])
cor(s$v[,1],s$v[,5])
cor(s$v[,2],s$v[,5])
library(GSE5859Subset)
data(GSE5859Subset)
s = svd(geneExpression-rowMeans(geneExpression))
z = s$d * t(s$v)
which.max(cor(sampleInfo$g,s$v)
)
cor(sampleInfo$g ,s$v[,1])
cor(sampleInfo$g ,s$v[,2])
cor(sampleInfo$g ,s$v[,3])
cor(sampleInfo$g ,s$v[,4])
cor(sampleInfo$g ,s$v[,5])
cor(sampleInfo$g ,s$v[,6])
cor(sampleInfo$g ,s$v[,7])
prComp = prcomp (e)
prComp = prcomp(geneExpression)
cor(prComp$x[,1],sampleInfo$g)
dim(prComp$x)
cor(prComp$x[1,],sampleInfo$g)
cor(prComp$x[2,],sampleInfo$g)
cor(prComp$x[3,],sampleInfo$g)
cor(prComp$x[4,],sampleInfo$g)
cor(prComp$x[5,],sampleInfo$g)
cor(prComp$x[6,],sampleInfo$g)
cor(prComp$x[7,],sampleInfo$g)
cor(prComp$x[8,],sampleInfo$g)
help(prcomp)
dim(prComp$rotation)
View(prComp$rotation)
svd = svd(geneExpression- rowMeans(geneExpression))
View(svd$v)
cor(svd$v[,1],svd$v[,2])
cor(prComp$rotation[,1],prComp$rotation[,2])
cor(prComp$rotation[1,],prComp$rotation[2,])
cor(prComp$rotation[,1],samplInfo$g)
cor(prComp$rotation[,1],sampleInfo$g)
cor(prComp$rotation[,2],sampleInfo$g)
cor(prComp$rotation[,3],sampleInfo$g)
cor(prComp$rotation[,4],sampleInfo$g)
cor(prComp$rotation[,5],sampleInfo$g)
cor(prComp$rotation[,6],sampleInfo$g)
cor(prComp$rotation[,7],sampleInfo$g)
which.max(prComp$rotation,sampleInfo$g)
which.max(cor(prComp$rotation,sampleInfo$g))
sd(prComp$x[,1])
sd(prComp$x[,2])
sd(prComp$x[,3])
sd(prComp$x[,4])
sd(prComp$rotation[,4])
sd(prComp$rotation[,1])
sd(prComp$rotation[,2])
sd(prComp$rotation[,3])
sd(prComp$rotation[,4])
dim(prComp$rotation)
for(i in 1:5) print( round( cor( prComp$rotation[,i],s$v[,i]),3))
dim(s$v)
library(tissuesGeneExpression)
data(tissuesGeneExpression)
y = e - rowMeans(e)
s = svd(y)
prComp = prcomp(geneExpression)
dim(prComp$rotation)
for(i in 1:5) print( round( cor( prComp$rotation[,i],s$v[,i]),3))
dim(s$v)
prComp = prcomp(e)
for(i in 1:5) print( round( cor( prComp$rotation[,i],s$v[,i]),3))
plot(s$v[,2],prComp$rotation[,2])
library(tissuesGeneExpression)
data(tissuesGeneExpression)
y = e - rowMeans(e)
s = svd(y)
z = s$d * t(s$v)
prComp = prcomp(y)
plot(prComp$x[,1],s$v[,1])
plot(prComp$rotation[,1],s$v[,1])
library(GSE5859Subset)
library(rafalib)
data(GSE5859Subset)
y = geneExpression - rowMeans(geneExpression)
s = svd(y)
prComp = prcomp(y)
plot(s$v[,1],prComp$rotation[,1])
prComp = prcomp(geneExpression)
plot(s$v[,1],prComp$rotation[,1])
prComp = prcomp(y)
plot(s$v[,1],prComp$rotation[,1])
s = svd(geneExpression)
prComp = prcomp(geneExpression)
plot(s$v[,1],prComp$rotation[,1])
library(foreach)
library(doParallel) #setup parallel back end to use 8 processors
cl<-makeCluster(2)registerDoParallel(cl) # divide row size by 20, sample data 400 times
predictions<-foreach(m=1:400,.combine=cbind) %dopar% {
# using sample function without seed
sampleRows <- sample(nrow(traindf), size=floor((nrow(traindf)/length_divisor)))
fit <- ctree(casual ~ ., data = traindf[sampleRows,])
predictions <- data.frame(predict(object=fit, testdf[,predictorNames], se.fit = TRUE)[[1]])}
stopCluster(cl)
library(foreach)
library(doParallel) #setup parallel back end to use 8 processors
cl<-makeCluster(8)registerDoParallel(cl) # divide row size by 20, sample data 400 times
predictions<-foreach(m=1:400,.combine=cbind) %dopar% {
i = 1}
stopCluster(cl)
library(foreach)
library(doParallel) #setup parallel back end to use 8 processors
cl<-makeCluster(8)
registerDoParallel(cl)
predictions<-foreach(m=1:400,.combine=cbind) %dopar% {
i = 1])}
stopCluster(cl)
library(foreach)
library(doParallel) #setup parallel back end to use 8 processors
cl<-makeCluster(8)
registerDoParallel(cl)
length_divisor <- 20
predictions<-foreach(m=1:400,.combine=cbind) %dopar% {
i = 1 )}
stopCluster(cl)
library(foreach)
library(doParallel) #setup parallel back end to use 8 processors
cl<-makeCluster(8)
registerDoParallel(cl)
length_divisor <- 20
predictions<-foreach(m=1:400,.combine=cbind) %dopar% {
i = 1 }
stopCluster(cl)
help(array)
NITERATIONS=10
S = sample(c(rep(1,98),rep(0,727-98)))
N = rep(1,727)
M = 10000
prange = c(0,1)
sigmarange = c(0,1)
for(iteration in 1:NITERATIONS)
{
print(iteration)
p = runif(M,prange[1],prange[2])
sigma = runif(M,sigmarange[1],sigmarange[2])
use = 1:round(length(N)*iteration/NITERATIONS)
logp = dbinom(sum(S[use]),sum(N[use]),p*sigma,log=TRUE)+
dbeta(p,1,1,log=TRUE)+dbeta(sigma,630,136,log=TRUE)
logw = logp - dunif(p,prange[1],prange[2],log=TRUE)-
dunif(sigma,sigmarange[1],sigmarange[2],log=TRUE)
w = exp(logw-max(logw)); w=w/sum(w)
i = which(w>(mean(w)*0.05))
prange = range(p[i])
sigmarange = range(sigma[i])
}
plot(prange, sigmarange)
plot( sigmarange,prange)
NITERATIONS=1000
S = sample(c(rep(1,98),rep(0,727-98)))
N = rep(1,727)
M = 10000
prange = c(0,1)
sigmarange = c(0,1)
for(iteration in 1:NITERATIONS)
{
print(iteration)
p = runif(M,prange[1],prange[2])
sigma = runif(M,sigmarange[1],sigmarange[2])
use = 1:round(length(N)*iteration/NITERATIONS)
logp = dbinom(sum(S[use]),sum(N[use]),p*sigma,log=TRUE)+
dbeta(p,1,1,log=TRUE)+dbeta(sigma,630,136,log=TRUE)
logw = logp - dunif(p,prange[1],prange[2],log=TRUE)-
dunif(sigma,sigmarange[1],sigmarange[2],log=TRUE)
w = exp(logw-max(logw)); w=w/sum(w)
i = which(w>(mean(w)*0.05))
prange = range(p[i])
sigmarange = range(sigma[i])
}
plot( sigmarange,prange)
plot( sigmarange,prange)
sigmarange
prange
plot( sigma,p)
NITERATIONS=10
S = sample(c(rep(1,98),rep(0,727-98)))
N = rep(1,727)
M = 10000
prange = c(0,1)
sigmarange = c(0,1)
for(iteration in 1:NITERATIONS)
{
print(iteration)
p = runif(M,prange[1],prange[2])
sigma = runif(M,sigmarange[1],sigmarange[2])
use = 1:round(length(N)*iteration/NITERATIONS)
logp = dbinom(sum(S[use]),sum(N[use]),p*sigma,log=TRUE)+
dbeta(p,1,1,log=TRUE)+dbeta(sigma,630,136,log=TRUE)
logw = logp - dunif(p,prange[1],prange[2],log=TRUE)-
dunif(sigma,sigmarange[1],sigmarange[2],log=TRUE)
w = exp(logw-max(logw)); w=w/sum(w)
i = which(w>(mean(w)*0.05))
prange = range(p[i])
sigmarange = range(sigma[i])
}
sum(w)
w
(sum(w))^2/sum(w^2)
library(depmixS4)
lca<-read.table("http://www.ats.ucla.edu/stat/mplus/seminars/introMplus_part2/lca.dat", sep=",")
names(lca)<-c( "hm", "he", "voc", "nocol" ,"ach9", "ach10", "ach11","ach12")
mod <- mix(list(hm~1,he~1,voc~1,nocol~1,ach9~1,ach10~1 ,ach11~1 ,ach12~1  ), data=lca, nstates=2,
family=list(multinomial(),multinomial(),multinomial(),multinomial(), gaussian(),gaussian(),gaussian(),gaussian()),
respstart=runif(32))
fmod<-fit(mod)
summary(fmod)
help(mix)
fmod$response
str(fmod)
fmod
summary(fmod, which = "response")
summary(fmod, which = "prior")
summary(fmod)
summary(fmod, which = "nstates")
install.packages("HiddenMarkov")
library(HiddenMarkov)
help(HiddenMarkov)
help(depmixS4)
showcase("mix")
showClass(mix)
showClass("mix")
fmod@response
help(depmix)
fmod@transition
fmod@prior
fmod@stationary
fmod@nstate
fmod@nstates
fmod@ntimes
fmod@nresp
fmod@npars
data("speed")
set.seed(1)
mod <- depmix(response = rt ~ 1, data = speed, nstates = 2,  trstart = runif(4))
fm <- fit(mod, emc=em.control(rand=FALSE))
fm@transition
fm@response
summary(fm)
posterior(fm)
fm@response
lca<-read.table("http://www.ats.ucla.edu/stat/mplus/seminars/introMplus_part2/lca.dat", sep=",")
names(lca)<-c( "hm", "he", "voc", "nocol" ,"ach9", "ach10", "ach11","ach12")
mod <- mix(list(hm~1,he~1,voc~1,nocol~1,ach9~1,ach10~1 ,ach11~1 ,ach12~1  ), data=lca, nstates=2,
family=list(multinomial(),multinomial(),multinomial(),multinomial(), gaussian(),gaussian(),gaussian(),gaussian()),
respstart=runif(32))
fmod<-fit(mod)
summary(fmod)
summary(fmod)
summary(fm)
View(lca)
help(random)
help(rand)
sample(1:10,12,replace = T)
lca$he = sample(1:4,500, replace = T)
View(lca)
names(lca)<-c( "hm", "he", "voc", "nocol" ,"ach9", "ach10", "ach11","ach12")
mod <- mix(list(hm~1,he~1,voc~1,nocol~1,ach9~1,ach10~1 ,ach11~1 ,ach12~1  ), data=lca, nstates=2,
family=list(multinomial(),multinomial(),multinomial(),multinomial(), gaussian(),gaussian(),gaussian(),gaussian()),
respstart=runif(32))
fmod<-fit(mod)
summary(fmod)
names(lca)<-c( "hm", "he", "voc", "nocol" ,"ach9", "ach10", "ach11","ach12")
mod <- mix(list(hm~1,he~1,voc~1,nocol~1,ach9~1,ach10~1 ,ach11~1 ,ach12~1  ), data=lca, nstates=2,
family=list(multinomial(),multinomial(),multinomial(),multinomial(), gaussian(),gaussian(),gaussian(),gaussian()),
respstart=runif(36))
fmod<-fit(mod)
summary(fmod)
source("http://bioconductor.org/biocLite.R")
biocLite("VanillaICE")
library(depmixS4)
data(speed)
set.seed(1)
str(speed)
sample(1:2,4,replace = T)
speed$corr = sample(1:4,439,replaced = TRUE)
speed$corr = sample(1:4,439,replaced = T)
speed$corr = sample(1:4,439,replaced = True)
speed$corr = sample(1:4,439,replace = True)
speed$corr = sample(1:4,439,replace = T)
str(speed)
mod <- depmix(list(rt ~ 1,corr ~ 1), data = speed, nstates = 2,family = list(gaussian(), multinomial("identity")), transition = ~ scale(Pacc), instart = runif(2))
fm <- fit(mod, verbose = FALSE, emc=em.control(rand=FALSE))
summary(fm, which = "response")
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
library(dlm)
help(dlm)
help(diag)
diag(4)
matrix(c(-1, -1, -1, 1, 0, 0, 0, 1, 0)
)
matrix(c(-1, -1, -1, 1, 0, 0, 0, 1, 0)
)
diag(c(771.35, 86.48, 0, 0), nr = 4)
bdiag(1)
ar.sim<-arima.sim(model=list(ar=c(.9,-.2)),n=100)
ts.plot(ar.sim)
ar.acf<-acf(ar.sim,type="correlation",plot=T)
ma.sim<-arima.sim(model=list(ma=c(-.7,.1)),n=100)
ma.acf<-acf(ma.sim,type="correlation",plot=T)
ma.sim<-arima.sim(model=list(ma=c(-.7)),n=100)
ma.acf<-acf(ma.sim,type="correlation",plot=T)
ar.sim<-arima.sim(model=list(ar=c(.9)),n=100)
ar.acf<-acf(ar.sim,type="correlation",plot=T)
ar.sim<-arima.sim(model=list(ar= .9,n=100)
)
help(ar)
acf(diff(Z.ts))
www <- "http://www.massey.ac.nz/~pscowper/ts/pounds_nz.dat"
Z <- read.table(www, header = T)
setwd("~/Documents/GitHub/Glaucoma_Python/Glaucoma_V0.0.1/Output")
UsualCare = read.csv("MList_UsualCare.csv",header = T)
View(UsualCare)
15Target = read.csv("MList_15Target.csv",header = T)
Target15 = read.csv("MList_15Target.csv",header = T)
Month6 = read.csv ("MList_6Month.csv",header = T)
View(Month6)
Month24 = read.csv ("MList_24Month.csv",header = T)
UsualCare$Type = "UsualCare"
Target15$Type = "Target15"
Month6$Type = "Month6"
Month24$Type = "Month24"
Target15$QALY = Target15$QALY - UsualCare$QALY
Month6$QALY = Month6$QALY - UsualCare$QALY
Month24$QALY = Month24$QALY- UsualCare$QALY
View(Month24)
Target15$TotalCost = Target15$TotalCost - UsualCare$TotalCost
Month6$TotalCost = Month6$TotalCost - UsualCare$TotalCost
Month24$TotalCost = Month24$TotalCost- UsualCare$TotalCost
MasterData = rbind(Target15,Month6,Month24)
library(ggplot2)
View(MasterData)
qplot(QALY,TotalCost,data = MasterData,color = Type)
UsualCare = read.csv("MList_Usual_100.csv",header = T)
Target15 = read.csv("MList_15_100.csv",header = T)
Month6 = read.csv ("MList_6_100.csv",header = T)
Month24 = read.csv ("MList_24_100.csv",header = T)
UsualCare$Type = "UsualCare"
Target15$Type = "Target15"
Month6$Type = "Month6"
Month24$Type = "Month24"
Target15$QALY = Target15$QALY - UsualCare$QALY
Month6$QALY = Month6$QALY - UsualCare$QALY
Month24$QALY = Month24$QALY- UsualCare$QALY
Target15$TotalCost = Target15$TotalCost - UsualCare$TotalCost
Month6$TotalCost = Month6$TotalCost - UsualCare$TotalCost
Month24$TotalCost = Month24$TotalCost- UsualCare$TotalCost
MasterData = rbind(Target15,Month6,Month24)
library(ggplot2)
qplot(QALY,TotalCost,data = MasterData,color = Type)
UsualCare = read.csv("Usual.csv",header = T)
Target15 = read.csv("15.csv",header = T)
Month6 = read.csv ("6.csv",header = T)
Month24 = read.csv ("24.csv",header = T)
UsualCare$Type = "UsualCare"
Target15$Type = "Target15"
Month6$Type = "Month6"
Month24$Type = "Month24"
#QALY
Target15$QALY = Target15$QALY - UsualCare$QALY
Month6$QALY = Month6$QALY - UsualCare$QALY
Month24$QALY = Month24$QALY- UsualCare$QALY
#TotalCost
Target15$TotalCost = Target15$TotalCost - UsualCare$TotalCost
Month6$TotalCost = Month6$TotalCost - UsualCare$TotalCost
Month24$TotalCost = Month24$TotalCost- UsualCare$TotalCost
MasterData = rbind(Target15,Month6,Month24)
library(ggplot2)
qplot(QALY,TotalCost,data = MasterData,color = Type)
